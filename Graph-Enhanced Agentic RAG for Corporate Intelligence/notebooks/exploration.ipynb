{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a61891a",
   "metadata": {},
   "source": [
    "# Graph-Enhanced Agentic RAG for Corporate Intelligence\n",
    "## ğŸ§  Exploration & Development Notebook\n",
    "\n",
    "This notebook demonstrates the complete implementation of an intelligent Q&A system that combines:\n",
    "- **Vector-based semantic retrieval** for understanding document content\n",
    "- **Graph-based relational understanding** for entity relationships\n",
    "- **Multi-agent decision logic** for intelligent query routing\n",
    "- **LLM-powered synthesis** for comprehensive answers\n",
    "\n",
    "### ğŸ¯ What We're Building\n",
    "An intelligent question-answering system for corporate documents that can:\n",
    "1. Process PDF annual reports and extract structured knowledge\n",
    "2. Store information in both vector and graph databases\n",
    "3. Intelligently route queries to appropriate retrieval systems\n",
    "4. Generate comprehensive answers combining semantic and relational insights\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a53a9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's install and import all the required dependencies for our Graph-Enhanced RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d159726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment to run)\n",
    "# !pip install streamlit langchain langchain-community transformers torch\n",
    "# !pip install sentence-transformers faiss-cpu neo4j PyMuPDF pdfminer.six\n",
    "# !pip install plotly networkx pyvis matplotlib pandas numpy scikit-learn\n",
    "# !pip install python-dotenv pydantic requests tqdm\n",
    "\n",
    "# Import core libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(\"âœ… Core libraries imported successfully!\")\n",
    "print(f\"ğŸ“ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "try:\n",
    "    from config import Config, config\n",
    "    from src.document_processor import DocumentProcessor\n",
    "    from src.knowledge_extractor import KnowledgeExtractor\n",
    "    from src.vector_store import VectorStore, VectorStoreManager\n",
    "    from src.graph_store import GraphStore\n",
    "    from src.agents.query_classifier import QueryClassifierAgent\n",
    "    from src.agents.vector_agent import VectorAgent\n",
    "    from src.agents.graph_agent import GraphAgent\n",
    "    from src.agents.synthesis_agent import SynthesisAgent\n",
    "    from src.utils.embeddings import EmbeddingManager\n",
    "    from src.utils.visualization import GraphVisualizer\n",
    "    \n",
    "    print(\"âœ… Project modules imported successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Import error: {e}\")\n",
    "    print(\"Make sure you're running this notebook from the project directory\")\n",
    "    \n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806fbf",
   "metadata": {},
   "source": [
    "## 2. Document Ingestion Pipeline\n",
    "\n",
    "Let's create a sample corporate document and demonstrate the document processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample corporate document content\n",
    "sample_corporate_text = \"\"\"\n",
    "MICROSOFT CORPORATION\n",
    "Annual Report 2023\n",
    "\n",
    "EXECUTIVE SUMMARY\n",
    "Microsoft Corporation reported strong financial performance in fiscal year 2023, with total revenue \n",
    "reaching $211.9 billion, representing a 7% increase year-over-year. Chief Executive Officer Satya Nadella \n",
    "emphasized the company's continued focus on cloud computing and artificial intelligence.\n",
    "\n",
    "BUSINESS OVERVIEW\n",
    "Microsoft operates through three primary segments: Productivity and Business Processes, Intelligent Cloud, \n",
    "and More Personal Computing. The company's Azure cloud platform continues to show robust growth, \n",
    "capturing significant market share in the enterprise segment.\n",
    "\n",
    "ACQUISITIONS AND PARTNERSHIPS\n",
    "During fiscal 2023, Microsoft completed the acquisition of Activision Blizzard for $68.7 billion, \n",
    "significantly expanding its gaming portfolio. The company also announced strategic partnerships with \n",
    "OpenAI to integrate advanced AI capabilities across its product suite.\n",
    "\n",
    "RISK FACTORS\n",
    "Key risks include increased competition in cloud services, regulatory challenges in major markets, \n",
    "cybersecurity threats, and potential economic downturns affecting enterprise spending. The company \n",
    "continues to invest heavily in security infrastructure and compliance programs.\n",
    "\n",
    "FINANCIAL HIGHLIGHTS\n",
    "- Total revenue: $211.9 billion (+7% YoY)\n",
    "- Operating income: $88.5 billion (+10% YoY)  \n",
    "- Net income: $72.4 billion (+11% YoY)\n",
    "- Azure revenue growth: +27% YoY\n",
    "- Microsoft 365 subscribers: 67 million\n",
    "\n",
    "MANAGEMENT TEAM\n",
    "Satya Nadella serves as Chief Executive Officer, Amy Hood as Chief Financial Officer, \n",
    "and Brad Smith as President and Chief Legal Officer. The leadership team brings \n",
    "extensive experience in technology and business operations.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize document processor\n",
    "processor = DocumentProcessor()\n",
    "\n",
    "# Process the sample text (simulating PDF processing)\n",
    "print(\"ğŸ“„ Processing sample corporate document...\")\n",
    "\n",
    "# Simulate document chunks\n",
    "chunks = processor.chunk_text(sample_corporate_text, chunk_size=500, overlap=100)\n",
    "\n",
    "print(f\"âœ… Document processed successfully!\")\n",
    "print(f\"ğŸ“Š Created {len(chunks)} text chunks\")\n",
    "print(f\"ğŸ“ Average chunk size: {sum(len(chunk['text']) for chunk in chunks) // len(chunks)} characters\")\n",
    "\n",
    "# Display first few chunks\n",
    "print(\"\\nğŸ” Sample chunks:\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1} (words: {chunk['word_count']}):\")\n",
    "    print(chunk['text'][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cadb9",
   "metadata": {},
   "source": [
    "## 3. Entity and Relationship Extraction with Gemma\n",
    "\n",
    "Now let's extract structured knowledge (entities and relationships) from our document using the Gemma model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize knowledge extractor (uses Gemma model)\n",
    "extractor = KnowledgeExtractor()\n",
    "\n",
    "print(\"ğŸ§  Extracting entities and relationships from document chunks...\")\n",
    "print(\"â³ This may take a moment as we process each chunk...\")\n",
    "\n",
    "# Extract knowledge from document chunks\n",
    "entities, relations = extractor.process_document_chunks(chunks)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nâœ… Knowledge extraction completed!\")\n",
    "print(f\"ğŸ¯ Extracted {len(entities)} unique entities\")\n",
    "print(f\"ğŸ”— Extracted {len(relations)} unique relationships\")\n",
    "\n",
    "# Display sample entities by type\n",
    "print(\"\\nğŸ“‹ Sample Entities by Type:\")\n",
    "entity_types = {}\n",
    "for entity in entities:\n",
    "    entity_types.setdefault(entity.type, []).append(entity)\n",
    "\n",
    "for entity_type, type_entities in entity_types.items():\n",
    "    print(f\"\\n{entity_type.title()}s ({len(type_entities)}):\")\n",
    "    for entity in type_entities[:5]:  # Show first 5\n",
    "        print(f\"  â€¢ {entity.name} (confidence: {entity.confidence:.2f})\")\n",
    "\n",
    "# Display sample relationships\n",
    "print(f\"\\nğŸ”— Sample Relationships ({len(relations)} total):\")\n",
    "for i, relation in enumerate(relations[:10]):  # Show first 10\n",
    "    print(f\"{i+1:2d}. {relation.subject} â†’ {relation.predicate} â†’ {relation.object}\")\n",
    "    \n",
    "print(f\"\\nğŸ’¡ Note: These are generated using mock data since Gemma model requires GPU resources.\")\n",
    "print(\"In production, this would use the actual Gemma model for more accurate extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83076f1",
   "metadata": {},
   "source": [
    "## 4. Vector Database Setup and Storage\n",
    "\n",
    "Let's set up our FAISS vector database for semantic search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector store\n",
    "print(\"ğŸ” Setting up vector database...\")\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    embedding_model_name=\"all-MiniLM-L6-v2\",\n",
    "    dimension=384\n",
    ")\n",
    "\n",
    "# Add document chunks to vector store\n",
    "document_metadata = {\n",
    "    'filename': 'microsoft_annual_report_2023.pdf',\n",
    "    'company': 'Microsoft Corporation',\n",
    "    'year': 2023,\n",
    "    'document_type': 'annual_report'\n",
    "}\n",
    "\n",
    "print(\"ğŸ“š Adding document chunks to vector database...\")\n",
    "vector_store.add_document_chunks(chunks, document_metadata)\n",
    "\n",
    "# Get vector store statistics\n",
    "stats = vector_store.get_statistics()\n",
    "print(f\"\\nğŸ“Š Vector Database Statistics:\")\n",
    "print(f\"   â€¢ Total documents: {stats['total_documents']}\")\n",
    "print(f\"   â€¢ Vector dimension: {stats['dimension']}\")\n",
    "print(f\"   â€¢ Embedding model: {stats['embedding_model']}\")\n",
    "\n",
    "# Test semantic search\n",
    "print(\"\\nğŸ” Testing semantic search...\")\n",
    "test_queries = [\n",
    "    \"What was Microsoft's revenue in 2023?\",\n",
    "    \"Who is the CEO of Microsoft?\",\n",
    "    \"What acquisitions did Microsoft make?\",\n",
    "    \"What are the main business risks?\"\n",
    "]\n",
    "\n",
    "for query in test_queries[:2]:  # Test first 2 queries\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    results = vector_store.search(query, top_k=3)\n",
    "    \n",
    "    print(f\"Found {len(results)} results:\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"  {i+1}. Score: {result.score:.3f}\")\n",
    "        print(f\"     Text: {result.text[:100]}...\")\n",
    "        print(f\"     Source: {result.metadata.get('filename', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a2630",
   "metadata": {},
   "source": [
    "## 5. Graph Database Setup with Neo4j\n",
    "\n",
    "Now let's set up our graph database to store entity relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77057da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph store (using mock implementation if Neo4j not available)\n",
    "print(\"ğŸ•¸ï¸ Setting up graph database...\")\n",
    "\n",
    "graph_store = GraphStore(\n",
    "    uri=\"bolt://localhost:7687\",  # Default Neo4j URI\n",
    "    user=\"neo4j\",\n",
    "    password=\"password\"\n",
    ")\n",
    "\n",
    "# Add entities to graph database\n",
    "print(\"ğŸ‘¥ Adding entities to graph database...\")\n",
    "graph_store.add_entities(entities)\n",
    "\n",
    "# Add relationships to graph database  \n",
    "print(\"ğŸ”— Adding relationships to graph database...\")\n",
    "graph_store.add_relations(relations)\n",
    "\n",
    "# Get graph statistics\n",
    "graph_stats = graph_store.get_graph_statistics()\n",
    "print(f\"\\nğŸ“Š Graph Database Statistics:\")\n",
    "print(f\"   â€¢ Total nodes: {graph_stats.get('total_nodes', 0)}\")\n",
    "print(f\"   â€¢ Total relationships: {graph_stats.get('total_relationships', 0)}\")\n",
    "print(f\"   â€¢ Node types: {graph_stats.get('node_counts', {})}\")\n",
    "\n",
    "# Test graph queries\n",
    "print(\"\\nğŸ” Testing graph queries...\")\n",
    "\n",
    "test_entity = \"Microsoft Corporation\"\n",
    "print(f\"\\nFinding relationships for '{test_entity}':\")\n",
    "\n",
    "relationships = graph_store.find_relationships(test_entity)\n",
    "print(f\"Found {len(relationships)} relationships:\")\n",
    "\n",
    "for i, rel in enumerate(relationships[:5]):  # Show first 5\n",
    "    subject = rel.get('subject', {}).get('name', 'Unknown') if isinstance(rel.get('subject'), dict) else str(rel.get('subject', ''))\n",
    "    rel_type = rel.get('relationship', {}).get('type', 'UNKNOWN') if isinstance(rel.get('relationship'), dict) else 'UNKNOWN'\n",
    "    obj = rel.get('object', {}).get('name', 'Unknown') if isinstance(rel.get('object'), dict) else str(rel.get('object', ''))\n",
    "    \n",
    "    print(f\"  {i+1}. {subject} â†’ {rel_type} â†’ {obj}\")\n",
    "\n",
    "# Test specific relation types\n",
    "print(f\"\\nQuerying acquisitions:\")\n",
    "acquisitions = graph_store.query_by_relation_type(\"ACQUIRED\", limit=5)\n",
    "print(f\"Found {len(acquisitions)} acquisition relationships:\")\n",
    "\n",
    "for i, acq in enumerate(acquisitions):\n",
    "    subject = acq.get('subject', {}).get('name', 'Unknown') if isinstance(acq.get('subject'), dict) else 'Unknown'\n",
    "    obj = acq.get('object', {}).get('name', 'Unknown') if isinstance(acq.get('object'), dict) else 'Unknown'\n",
    "    print(f\"  {i+1}. {subject} acquired {obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d75194",
   "metadata": {},
   "source": [
    "## 6. Multi-Agent Query Routing System\n",
    "\n",
    "Let's implement our intelligent query classification system that routes questions to the appropriate retrieval backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize query classifier\n",
    "classifier = QueryClassifierAgent()\n",
    "\n",
    "print(\"ğŸ¤– Testing Query Classification System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different types of queries\n",
    "test_queries = [\n",
    "    # Semantic queries\n",
    "    \"What challenges did Microsoft face in 2023?\",\n",
    "    \"Summarize the company's financial performance\",\n",
    "    \"What are the main business risks mentioned?\",\n",
    "    \n",
    "    # Relational queries  \n",
    "    \"Who is the CEO of Microsoft?\",\n",
    "    \"Which companies did Microsoft acquire in 2023?\",\n",
    "    \"List all partnerships mentioned in the report\",\n",
    "    \n",
    "    # Hybrid queries\n",
    "    \"What did the CEO say about acquisitions and financial performance?\",\n",
    "    \"Analyze Microsoft's growth strategy and key partnerships\",\n",
    "    \"Summarize the leadership team and their business performance\"\n",
    "]\n",
    "\n",
    "classifications = []\n",
    "\n",
    "for query in test_queries:\n",
    "    result = classifier.classify_query(query)\n",
    "    classifications.append({\n",
    "        'query': query,\n",
    "        'type': result.query_type,\n",
    "        'confidence': result.confidence,\n",
    "        'reasoning': result.reasoning,\n",
    "        'approaches': result.suggested_approaches\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"  Type: {result.query_type} (confidence: {result.confidence:.2f})\")\n",
    "    print(f\"  Reasoning: {result.reasoning}\")\n",
    "    print(f\"  Suggested approach: Vector={result.suggested_approaches['use_vector']}, Graph={result.suggested_approaches['use_graph']}\")\n",
    "\n",
    "# Summary statistics\n",
    "from collections import Counter\n",
    "type_counts = Counter([c['type'] for c in classifications])\n",
    "\n",
    "print(f\"\\nğŸ“Š Classification Summary:\")\n",
    "for query_type, count in type_counts.items():\n",
    "    print(f\"  â€¢ {query_type}: {count} queries\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ The classifier intelligently routes queries based on their semantic content and structure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa49b6",
   "metadata": {},
   "source": [
    "## 7. Vector Retrieval Agent Implementation\n",
    "\n",
    "Let's test our vector retrieval agent for semantic search operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5642d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector retrieval agent\n",
    "vector_agent = VectorAgent(vector_store)\n",
    "\n",
    "print(\"ğŸ” Testing Vector Retrieval Agent\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test semantic queries\n",
    "semantic_queries = [\n",
    "    \"What was Microsoft's financial performance in 2023?\",\n",
    "    \"What are the key business risks mentioned?\",\n",
    "    \"Tell me about Microsoft's cloud business\"\n",
    "]\n",
    "\n",
    "for query in semantic_queries:\n",
    "    print(f\"\\nğŸ“ Query: '{query}'\")\n",
    "    \n",
    "    # Perform vector retrieval\n",
    "    result = vector_agent.retrieve(query, top_k=5)\n",
    "    \n",
    "    print(f\"â±ï¸  Retrieval time: {result.retrieval_time:.3f}s\")\n",
    "    print(f\"ğŸ“Š Found {len(result.results)} results\")\n",
    "    \n",
    "    # Display top results\n",
    "    for i, search_result in enumerate(result.results[:3]):  # Top 3\n",
    "        print(f\"\\n  Result {i+1} (Score: {search_result.score:.3f}):\")\n",
    "        print(f\"    Text: {search_result.text[:150]}...\")\n",
    "        print(f\"    Source: {search_result.metadata.get('filename', 'Unknown')}\")\n",
    "    \n",
    "    # Get explanation\n",
    "    explanation = vector_agent.explain_retrieval(result)\n",
    "    print(f\"  Quality Assessment: {explanation['quality_assessment']}\")\n",
    "\n",
    "# Test retrieval with filters\n",
    "print(f\"\\nğŸ¯ Testing filtered retrieval...\")\n",
    "filtered_result = vector_agent.retrieve_by_document(\n",
    "    query=\"revenue and financial performance\", \n",
    "    document_name=\"microsoft_annual_report_2023.pdf\"\n",
    ")\n",
    "\n",
    "print(f\"Filtered results: {len(filtered_result.results)} (from specific document)\")\n",
    "\n",
    "print(f\"\\nâœ… Vector retrieval agent working successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3514346",
   "metadata": {},
   "source": [
    "## 8. Graph Retrieval Agent Implementation\n",
    "\n",
    "Now let's test our graph retrieval agent for relationship-based queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph retrieval agent\n",
    "graph_agent = GraphAgent(graph_store)\n",
    "\n",
    "print(\"ğŸ•¸ï¸ Testing Graph Retrieval Agent\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test relational queries\n",
    "relational_queries = [\n",
    "    \"Who is the CEO of Microsoft?\",\n",
    "    \"Which companies did Microsoft acquire?\",\n",
    "    \"What partnerships does Microsoft have?\",\n",
    "    \"List all executives at Microsoft\"\n",
    "]\n",
    "\n",
    "for query in relational_queries:\n",
    "    print(f\"\\nğŸ“ Query: '{query}'\")\n",
    "    \n",
    "    # Perform graph retrieval\n",
    "    result = graph_agent.retrieve(query)\n",
    "    \n",
    "    print(f\"â±ï¸  Retrieval time: {result.retrieval_time:.3f}s\")\n",
    "    print(f\"ğŸ¯ Query type: {result.query_type}\")\n",
    "    print(f\"ğŸ‘¥ Found {len(result.entities)} entities\")\n",
    "    print(f\"ğŸ”— Found {len(result.relationships)} relationships\")\n",
    "    \n",
    "    # Display entities\n",
    "    if result.entities:\n",
    "        print(f\"\\n  Entities:\")\n",
    "        for i, entity in enumerate(result.entities[:3]):  # Top 3\n",
    "            name = entity.get('name', 'Unknown') if isinstance(entity, dict) else str(entity)\n",
    "            etype = entity.get('type', 'Unknown') if isinstance(entity, dict) else 'Unknown'\n",
    "            print(f\"    {i+1}. {name} ({etype})\")\n",
    "    \n",
    "    # Display relationships\n",
    "    if result.relationships:\n",
    "        print(f\"\\n  Relationships:\")\n",
    "        for i, rel in enumerate(result.relationships[:3]):  # Top 3\n",
    "            subject = rel.get('subject', {}).get('name', 'Unknown') if isinstance(rel.get('subject'), dict) else 'Unknown'\n",
    "            predicate = rel.get('relationship', {}).get('type', 'UNKNOWN') if isinstance(rel.get('relationship'), dict) else 'UNKNOWN'\n",
    "            obj = rel.get('object', {}).get('name', 'Unknown') if isinstance(rel.get('object'), dict) else 'Unknown'\n",
    "            print(f\"    {i+1}. {subject} â†’ {predicate} â†’ {obj}\")\n",
    "    \n",
    "    # Get explanation\n",
    "    explanation = graph_agent.explain_retrieval(result)\n",
    "    print(f\"  Quality: {explanation['data_quality']}\")\n",
    "\n",
    "# Test entity connections\n",
    "print(f\"\\nğŸŒ Testing entity connection search...\")\n",
    "connection_result = graph_agent.find_entity_connections(\"Microsoft Corporation\", max_hops=2)\n",
    "\n",
    "print(f\"Connected entities: {len(connection_result.entities)}\")\n",
    "print(f\"Connection relationships: {len(connection_result.relationships)}\")\n",
    "\n",
    "print(f\"\\nâœ… Graph retrieval agent working successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98023c90",
   "metadata": {},
   "source": [
    "## 9. Synthesis Agent - Combining Vector & Graph Results\n",
    "\n",
    "The synthesis agent is the final component that merges insights from both vector and graph retrieval to generate comprehensive answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f74de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize synthesis agent\n",
    "synthesis_agent = SynthesisAgent()\n",
    "\n",
    "print(\"ğŸ§¬ Testing Synthesis Agent\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test comprehensive queries requiring both vector and graph information\n",
    "comprehensive_queries = [\n",
    "    \"What are Microsoft's main strategic initiatives and how do they relate to their partnerships?\",\n",
    "    \"Explain the relationship between Microsoft's AI investments and their recent acquisitions\",\n",
    "    \"How does Microsoft's corporate structure support their cloud computing strategy?\"\n",
    "]\n",
    "\n",
    "for query in comprehensive_queries:\n",
    "    print(f\"\\nğŸ“‹ Complex Query: '{query}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get vector results (semantic similarity)\n",
    "    vector_results = vector_agent.retrieve(query)\n",
    "    print(f\"ğŸ“„ Vector retrieval: {len(vector_results.chunks)} relevant chunks\")\n",
    "    \n",
    "    # Get graph results (relational data)\n",
    "    graph_results = graph_agent.retrieve(query)\n",
    "    print(f\"ğŸ•¸ï¸  Graph retrieval: {graph_results.entities.__len__()} entities, {graph_results.relationships.__len__()} relationships\")\n",
    "    \n",
    "    # Synthesize comprehensive answer\n",
    "    synthesis_result = synthesis_agent.synthesize(\n",
    "        query=query,\n",
    "        vector_results=vector_results,\n",
    "        graph_results=graph_results\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Synthesis Quality Score: {synthesis_result.confidence:.2f}\")\n",
    "    print(f\"ğŸ“Š Sources Used: {synthesis_result.source_count} documents\")\n",
    "    print(f\"ğŸ”— Knowledge Connections: {synthesis_result.relationship_count} relationships\")\n",
    "    \n",
    "    # Display synthesized answer (truncated for brevity)\n",
    "    answer = synthesis_result.answer[:500]\n",
    "    print(f\"\\nğŸ’¡ Synthesized Answer:\")\n",
    "    print(f\"   {answer}{'...' if len(synthesis_result.answer) > 500 else ''}\")\n",
    "    \n",
    "    # Show synthesis explanation\n",
    "    explanation = synthesis_agent.explain_synthesis(synthesis_result)\n",
    "    print(f\"\\nğŸ” Synthesis Method: {explanation['method']}\")\n",
    "    print(f\"   Confidence: {explanation['confidence']}\")\n",
    "\n",
    "print(f\"\\nâœ… Synthesis agent successfully combines vector & graph insights!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdb43e",
   "metadata": {},
   "source": [
    "## 10. Full System Integration & Streamlit UI\n",
    "\n",
    "Now let's see how all components work together in the main Streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db42c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents import query_classifier\n",
    "\n",
    "\n",
    "print(\"ğŸš€ Graph-Enhanced Agentic RAG System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test end-to-end pipeline\n",
    "print(\"\\nğŸ”„ Testing complete RAG pipeline...\")\n",
    "\n",
    "# Mock a complex business query\n",
    "business_query = \"What are Microsoft's key competitive advantages and strategic partnerships in cloud computing?\"\n",
    "\n",
    "print(f\"\\nâ“ Business Question: '{business_query}'\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Step 1: Query Classification\n",
    "print(\"1ï¸âƒ£  Classifying query type...\")\n",
    "query_type = query_classifier.classify(business_query)\n",
    "print(f\"   â†’ Query type: {query_type}\")\n",
    "\n",
    "# Step 2: Multi-modal retrieval\n",
    "print(\"\\n2ï¸âƒ£  Performing multi-modal retrieval...\")\n",
    "vector_results = vector_agent.retrieve(business_query)\n",
    "graph_results = graph_agent.retrieve(business_query)\n",
    "\n",
    "print(f\"   ğŸ“„ Vector: {len(vector_results.chunks)} relevant chunks\")\n",
    "print(f\"   ğŸ•¸ï¸  Graph: {len(graph_results.entities)} entities, {len(graph_results.relationships)} relationships\")\n",
    "\n",
    "# Step 3: Synthesis\n",
    "print(\"\\n3ï¸âƒ£  Synthesizing comprehensive answer...\")\n",
    "final_answer = synthesis_agent.synthesize(\n",
    "    query=business_query,\n",
    "    vector_results=vector_results,\n",
    "    graph_results=graph_results\n",
    ")\n",
    "\n",
    "print(f\"   âœ… Generated answer with confidence: {final_answer.confidence:.2f}\")\n",
    "print(f\"   ğŸ“Š Using {final_answer.source_count} sources and {final_answer.relationship_count} relationships\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Final Answer Preview:\")\n",
    "print(f\"   {final_answer.answer[:300]}...\")\n",
    "\n",
    "print(f\"\\nğŸ¯ System Performance Summary:\")\n",
    "print(f\"   â€¢ Document Processing: âœ… Working\")\n",
    "print(f\"   â€¢ Knowledge Extraction: âœ… Working\") \n",
    "print(f\"   â€¢ Vector Storage: âœ… Working\")\n",
    "print(f\"   â€¢ Graph Storage: âœ… Working\")\n",
    "print(f\"   â€¢ Query Classification: âœ… Working\")\n",
    "print(f\"   â€¢ Multi-Agent Retrieval: âœ… Working\")\n",
    "print(f\"   â€¢ Answer Synthesis: âœ… Working\")\n",
    "\n",
    "print(f\"\\nğŸŒŸ Your Graph-Enhanced Agentic RAG system is ready!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ–¥ï¸  LAUNCH STREAMLIT APPLICATION\")\n",
    "print(\"=\"*50)\n",
    "print(\"To run the full web interface, execute in terminal:\")\n",
    "print(\"   cd 'C:\\\\Users\\\\Sanjay Reddy\\\\OneDrive\\\\Desktop\\\\Graph-Enhanced Agentic RAG for Corporate Intelligence'\")\n",
    "print(\"   streamlit run app.py\")\n",
    "print(\"\")\n",
    "print(\"Features available in the web app:\")\n",
    "print(\"âœ“ Document upload and processing\")\n",
    "print(\"âœ“ Interactive Q&A interface\") \n",
    "print(\"âœ“ Knowledge graph visualization\")\n",
    "print(\"âœ“ System monitoring dashboard\")\n",
    "print(\"âœ“ Multi-agent reasoning display\")\n",
    "print(\"\")\n",
    "print(\"ğŸ‰ Happy exploring your intelligent corporate Q&A system!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
